# ML Service (`ml-service`)

## ğŸ“– Overview
The **ML Service** is a Python-based microservice responsible for detecting anomalies in financial transactions using **Isolation Forest** machine learning. It operates in two modes:

1. **Inference (Real-time)**: Consumes Kafka stream, extracts features, applies ML model, produces anomaly verdicts
2. **Training (Batch)**: Generates/loads training data, trains Isolation Forest, saves model artifacts

## ğŸ— Architecture
- **Language**: Python 3.11+
- **Framework**: FastAPI + Uvicorn
- **ML**: scikit-learn (Isolation Forest)
- **Message Broker**: Kafka (Redpanda for local dev)
- **Hot Feature Store**: Redis (velocity, user cache)
- **Persistent Store**: PostgreSQL (user profiles, transactions)
- **Model Storage**: Local filesystem (S3/R2 ready)

### Hybrid Storage Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transaction â”‚â”€â”€â”€â–ºâ”‚            ML Service             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                                    â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
           â”‚ Redis Cache â”‚â—„â”€â”€â”€ Cache Miss â”€â”€â”€â”€â”€â”€â”‚  PostgreSQL â”‚
           â”‚ (Hot Data)  â”‚                      â”‚ (Cold Data) â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â€¢ 1ms Read Time                      â€¢ Persistent
           â€¢ User Velocity                      â€¢ User Profiles
           â€¢ 100% Availability                  â€¢ Transactions
```

## ğŸ“ Project Structure
```
ml-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py           # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py         # Pydantic settings
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py     # REST API endpoints
â”‚   â”‚   â””â”€â”€ schemas.py    # Pydantic models
â”‚   â”œâ”€â”€ kafka/
â”‚   â”‚   â”œâ”€â”€ consumer.py   # Transaction consumer
â”‚   â”‚   â””â”€â”€ producer.py   # Anomaly producer
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ model.py      # Isolation Forest wrapper
â”‚   â”‚   â”œâ”€â”€ features.py   # Feature engineering (10 features)
â”‚   â”‚   â”œâ”€â”€ training.py   # Training pipeline
â”‚   â”‚   â””â”€â”€ scheduler.py  # Daily auto-retraining
â”‚   â””â”€â”€ repositories/
â”‚       â””â”€â”€ profile_repository.py  # Hybrid Redis+PostgreSQL repo
â”œâ”€â”€ models/               # Trained model files
â”œâ”€â”€ data/                 # Local data storage
â”œâ”€â”€ tests/                # Comprehensive tests
â”œâ”€â”€ docker-compose.yml    # Local dev environment
â”œâ”€â”€ Dockerfile
â””â”€â”€ pyproject.toml
```

---

## ğŸš€ Quick Start

### 1. Setup Environment
```bash
cd backend/services/ml-service

# Copy environment template
cp .env.example .env

# Install Python dependencies
pip install -e .
```

### 2. Start Local Services (Kafka + Redis + Postgres)
```bash
docker compose up -d redpanda redis redpanda-console postgres
```

### 3. Run the ML Service
```bash
# Development mode with hot reload
uvicorn src.main:app --reload --port 8000

# Or run directly
python -m src.main
```

### 4. Train Initial Model
```bash
# Trigger training via API
curl -X POST http://localhost:8000/v1/train \
  -H "Content-Type: application/json" \
  -d '{}'

# Check training status
curl http://localhost:8000/v1/train/<job_id>
```

### 5. Test Inference
```bash
curl -X POST http://localhost:8000/v1/inference \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user_123",
    "transaction": {
      "tx_id": "tx_test_001",
      "amount": 5000.00,
      "currency": "USD",
      "merchant": "Test Store"
    }
  }'
```

---

## ğŸ”„ Complete Data Flow

### 1. Ingestion â†’ ML Service (Real-Time)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client App â”‚â”€â”€â”€â–¶â”‚ Ingestion Svc   â”‚â”€â”€â”€â–¶â”‚ Kafka          â”‚
â”‚  POST /tx   â”‚    â”‚ Validates &     â”‚    â”‚ `transactions` â”‚
â”‚             â”‚    â”‚ Publishes       â”‚    â”‚ topic          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚                   ML Service                       â”‚
                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                   â”‚  â”‚ Kafka    â”‚â”€â”€â”€â–¶â”‚ Feature  â”‚â”€â”€â”€â–¶â”‚ Isolation    â”‚ â”‚
                   â”‚  â”‚ Consumer â”‚    â”‚ Engineer â”‚    â”‚ Forest Model â”‚ â”‚
                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ (Redis)  â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                   â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚         â”‚
                   â”‚                                         â–¼         â”‚
                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
                   â”‚  â”‚ Verdict Generator                        â”‚     â”‚
                   â”‚  â”‚ - Severity: LOW/MEDIUM/HIGH/CRITICAL     â”‚     â”‚
                   â”‚  â”‚ - Explanation: "Amount 37x above avg..." â”‚     â”‚
                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚            Kafka `anomalies` topic                 â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                   â”‚                           â”‚
       â–¼                                   â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dashboard    â”‚                  â”‚ Notification â”‚            â”‚ Database     â”‚
â”‚ (Real-time)  â”‚                  â”‚ Service      â”‚            â”‚ (Postgres)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚ (Alerts)     â”‚            â”‚ Store for    â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ history      â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Scheduled Retraining Flow (Every 24h)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Daily Trigger  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Count < 1000
â”‚   Check Data    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [ Skip Retrain ]
â”‚     Volume      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Count >= 1000
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fetch Last 7 Daysâ”‚â—„â”€â”€â”€â”€â”¤  PostgreSQL   â”‚
â”‚   Transactions  â”‚      â”‚ (Transactions)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Extract Featuresâ”‚â—„â”€â”€â”€â”€â”¤  PostgreSQL   â”‚
â”‚ (& User Profiles)â”‚      â”‚  (Profiles)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Train New     â”‚
â”‚ Isolation Forestâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Validation Fail
â”‚ Validate Model  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [ Keep Old Model ]
â”‚ (Anomaly Rate)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Validation Pass
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Save & Promote  â”‚
â”‚   New Version   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Feature Engineering (10 Features)

User-specific features stored in Redis/Postgres:

| Feature | Description | User-Specific? |
|---------|-------------|----------------|
| `log_amount` | Log-transformed amount | âŒ |
| `amount_zscore` | How many std from user's avg | âœ… |
| `amount_percentile` | Where in user's history | âœ… |
| `velocity_ratio` | Current / user's typical rate | âœ… |
| `hour_deviation` | Unusual hour for this user? | âœ… |
| `day_deviation` | Unusual day for this user? | âœ… |
| `time_since_last` | Seconds since last tx | âœ… |
| `merchant_familiarity` | Known merchant? | âœ… |
| `is_new_user` | < 20 transactions | âœ… |
| `global_amount_flag` | Globally unusual | âŒ |

---

## ğŸ”Œ API Reference

### Health Check
**GET** `/v1/health`

### Retraining Controls
**GET** `/v1/retrain/status` - Check next scheduled retrain  
**POST** `/v1/retrain/trigger` - Force manual retrain

### User Profiles
**GET** `/v1/users/{user_id}/profile` - Get behavioral profile
**DELETE** `/v1/users/{user_id}/profile` - Reset profile (testing)

### Inference
**POST** `/v1/inference` - Run inference with user context

---

## ğŸ“Š Ports & Services (Local Dev)

| Service | Port | URL |
|---------|------|-----|
| ML Service | 8000 | http://localhost:8000 |
| ML Service Docs | 8000 | http://localhost:8000/docs |
| Redpanda Console | 8080 | http://localhost:8080 |
| Kafka | 9092 | localhost:9092 |
| Redis | 6379 | localhost:6379 |

---

## ğŸ”§ Environment Variables

See `.env.example` for all configuration options. Key settings:

| Variable | Description | Default |
|----------|-------------|---------|
| `KAFKA_BOOTSTRAP_SERVERS` | Kafka broker address | localhost:9092 |
| `REDIS_URL` | Redis connection string | redis://localhost:6379/0 |
| `DATABASE_URL` | PostgreSQL connection string | None (optional) |
| `MODEL_PATH` | Path to model file | ./models/current_model.pkl |
| `ANOMALY_THRESHOLD` | Score threshold for anomaly | 0.5 |
